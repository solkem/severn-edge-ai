#include "inference.h"

// NOTE: TensorFlow Lite Micro integration will be added after model training
// For now, we'll create the buffer management and placeholder functions

// ============================================================================
// Sliding Window Buffer
// ============================================================================
static int16_t sampleBuffer[WINDOW_SIZE][6];  // 100 samples Ã— 6 axes
static int sampleIndex = 0;

// ============================================================================
// Placeholder Model (will be replaced with trained model)
// ============================================================================
// This will be generated by the training pipeline and embedded as model.h
static const unsigned char model_data[] = {0};  // Placeholder

// ============================================================================
// TFLite Objects (to be initialized when TFLite is integrated)
// ============================================================================
// tflite::MicroInterpreter* interpreter = nullptr;
// TfLiteTensor* input = nullptr;
// TfLiteTensor* output = nullptr;
// uint8_t tensor_arena[TENSOR_ARENA_SIZE];

bool setupInference() {
    DEBUG_PRINTLN("Setting up inference engine...");

    // TODO: Initialize TFLite interpreter when model is available
    // For now, just reset the buffer
    sampleIndex = 0;
    memset(sampleBuffer, 0, sizeof(sampleBuffer));

    DEBUG_PRINTLN("Inference engine ready (placeholder mode)");
    return true;
}

void addSample(int16_t ax, int16_t ay, int16_t az, int16_t gx, int16_t gy, int16_t gz) {
    if (sampleIndex < WINDOW_SIZE) {
        sampleBuffer[sampleIndex][0] = ax;
        sampleBuffer[sampleIndex][1] = ay;
        sampleBuffer[sampleIndex][2] = az;
        sampleBuffer[sampleIndex][3] = gx;
        sampleBuffer[sampleIndex][4] = gy;
        sampleBuffer[sampleIndex][5] = gz;
        sampleIndex++;
    }
}

bool isWindowReady() {
    return sampleIndex >= WINDOW_SIZE;
}

int runInference(float* confidence) {
    if (!isWindowReady()) {
        *confidence = 0.0f;
        return -1;
    }

    // TODO: Implement actual TFLite inference
    // For now, return a placeholder prediction
    *confidence = 0.85f;  // Fake confidence

    DEBUG_PRINTLN("Running inference (placeholder)");

    return 0;  // Fake prediction: class 0
}

void slideWindow() {
    // Keep the last (WINDOW_SIZE - WINDOW_STRIDE) samples
    int keep = WINDOW_SIZE - WINDOW_STRIDE;

    // Shift samples to the beginning
    for (int i = 0; i < keep; i++) {
        for (int j = 0; j < 6; j++) {
            sampleBuffer[i][j] = sampleBuffer[i + WINDOW_STRIDE][j];
        }
    }

    // Reset index to start filling from the kept samples
    sampleIndex = keep;
}

int getSampleCount() {
    return sampleIndex;
}
